datasets: 
  ds004101: "/data/origami/jacob/neuroci_test/nipoppy_datasets/ds004101_nipoppy" # OpenNeuro - https://openneuro.org/datasets/ds004101/versions/1.0.1
  ds006267: "/data/origami/jacob/neuroci_test/nipoppy_datasets/ds006267_nipoppy" # OpenNeuro - https://openneuro.org/datasets/ds006267/versions/1.0.0
  FastSurfer: "/data/origami/jacob/neuroci_test/nipoppy_datasets/FastSurferAnonBIDS_nipoppy" # Small FastSurfer train/test/validation set, sampled from many datasets.
  PreventAD: "/data/origami/jacob/neuroci_test/nipoppy_datasets/preventAD" # https://douglas.research.mcgill.ca/prevent-alzheimer-program/, only the T1s.

pipelines: # Use the *exact* same pipeline names and versions specified in the Nipoppy datasets above
  fslanat6071ants243: "6.0.7.1"
  freesurfer8001ants243: "8.0.0.1"
  freesurfer741ants243: "7.4.1"
  samseg8001ants243: "8.0.0.1"

userscripts: # Python scripts stored in the user_scripts directory in the repository
  script1: "userscript1.py"
  script2: "userscript2.py"

target_host: "ducky" # The target HPC host. Must be the name of a host that is specified in the SSH config file
prefix_cmd: "source /data/origami/jacob/neuroci_test/venv_pypi/bin/activate" # Prefix command (e.g. activating a virtual environment with Nipoppy installed in it)
scheduler: "sge" # Scheduler to use (slurm and sge are currently functional)
max_dl_size_per_dataset_tool_mb: 400 # The maximum size (in megabytes) that a tar file for a given dataset/pipeline derivatives can be for downloading onto the CI
