datasets: 
#  FastSurfer: "/data/origami/jacob/neuroci_test/nipoppy_datasets/FastSurferAnonBIDS_nipoppy" # Small FastSurfer train/test/validation set, sampled from many datasets.
#  PreventAD: "/data/origami/jacob/neuroci_test/nipoppy_datasets/preventAD" # https://douglas.research.mcgill.ca/prevent-alzheimer-program/, only the T1s.
  Rockland: "/data/origami/jacob/neuroci_test/nipoppy_datasets/NKI_nipoppy" # NKI Rockland Sample - https://github.com/ReproBrainChart/NKI_BIDS / https://reprobrainchart.github.io/docs/datasets/
  ds005752: "/data/origami/jacob/neuroci_test/nipoppy_datasets/ds005752_nipoppy" # OpenNeuro - https://openneuro.org/datasets/ds005752/versions/2.1.0
  ds003592: "/data/origami/jacob/neuroci_test/nipoppy_datasets/ds003592_nipoppy" # OpenNeuro - https://openneuro.org/datasets/ds003592/versions/1.0.13
  ds002345: "/data/origami/jacob/neuroci_test/nipoppy_datasets/ds002345_nipoppy" # OpenNeuro - https://openneuro.org/datasets/ds002345/versions/1.1.4
  

pipelines: # Use the *exact* same pipeline names and versions specified in the Nipoppy datasets above
  fslanat6071ants243: "6.0.7.1"
  freesurfer8001ants243: "8.0.0.1"
  freesurfer741ants243: "7.4.1"
  samseg8001ants243: "8.0.0.1"

userscripts: # Python scripts stored in the user_scripts directory in the repository.
  script1: "userscript1.py" # Build table of volumetry
  script2: "userscript2.py" # Plot volume correlations and distributions
  script3: "userscript3.py" # Demographic analyses

target_host: "ducky" # The target HPC host. Must be the name of a host that is specified in the SSH config file.
prefix_cmd: "source /data/origami/jacob/neuroci_test/venv_pypi/bin/activate" # Prefix command (e.g. activating a virtual environment with Nipoppy installed in it)
scheduler: "sge" # Scheduler to use (slurm and sge are currently functional)
max_dl_size_per_dataset_tool_mb: 400 # The maximum size (in megabytes) that a tar file for a given dataset/pipeline derivatives can be for downloading onto the CI
